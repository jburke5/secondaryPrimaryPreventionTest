{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>premise:</b> qalys due to risk-preventing treatment are overestimated in patients with non-fatal stroke or MI\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>elaboration:</b> the apparent effect of secondary prevention is the sum of two effects = \n",
    "<ol>\n",
    "<li> a revised version of the primary prevention effect. conditional on having had a first event, risk for subsequent events is higher, even if that first event does not causally increase your risk of a second event directly. (i.e. the first event is telling me information that was not evident when i observed your baseline risk). </li>\n",
    "<li> the causal effect due to pathologic changes caused by the non-fatal event. (e.g. because i had a stroke, my mobility was decreased and i gained weight and my blood pressure increased)</li>\n",
    "</ol>\n",
    "\n",
    "this is a potentially big problem because its likely that most of the increased risk observed in secondary prevention contexts is due to #1, not #2. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>example:</b> an individual has a baseline risk of stroke of 10% per year. assuming a treatment with a 25% RRR, then have a 2.5% ARR in year 1 (t=0 to t=1) that is causally related to treatment. then they have a TIA which results in no fundamental increase in risk. TIA appears to increases risk solely through mechanism #1, doubling the baseline risk. so, their  risk of stroke in year 2 (t=1 to t=2) is 20%. assuming a treatment with a 25% RRR, the year 2 ARR is 5%. \n",
    "\n",
    "<i>but, that  can’t be right.</i> the casual effect of treatment can’t change — nothing changed in that individual. the true casual effect can’t be different in those two time periods…at the individual level we are either overestimating the casual effect in year 2 or underestimating it in year 1.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>working that out in detail:</b> let's do a simple sim in a population with:\n",
    "<ol>\n",
    "    <li>a known “true” baseline risk</li>\n",
    "    <li>100% treatment adherence</li>\n",
    "    <li>a constant treatment effect (in primary and secondary prevention)</li>\n",
    "    <li> zero fatal events</li>\n",
    "    <li>the secondary prevention population has the same basline risk distribution, but twice the baseline mean risk</li>\n",
    "    <li> there are no other causal factors in the seconeary prevention population that drive risk</li>\n",
    "</ol>    \n",
    "this lets us estimate ehe “true causal effect” of treatment = baseline risk * treamtent effect.\n",
    "<p>this is the worst case scenario for over-estimation in the primary vs. secondary populaitons. with this setup, we can estimate what a simulation would find based on the basline risk assumption and the doubling of baseline risk in secondary prevention— when having an event doubles your baseline risk for identifying subsequent events. then we can estimate the “observed effect” (as it would be observed in a sim) by taking the baseline risk using it, by chance, to generate events and then doubling the baseline risk when you get into secondary prevention mode and then applying treatment effects at each stage based on your perceived risk (i.e. primary prevention risk prior to an event and the doubled secondary prevention risk thereafter). then we can let it run for 10 years...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume that everybody starts event free and everybody is treated. We'll look at multiple time epochs (e.g. t1 (year 0-> year1), t2 (year 1->2) and t3 (year 2->3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup a baseline risk distribution and define baseline assumptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "\n",
    "# this function takes a baseline event rate and randomly reverses it based on the magnitude of the treatment effect\n",
    "def applyTreatment(rrr,x ):\n",
    "    returnVal = -1\n",
    "    if x ==1:\n",
    "        returnVal = np.random.uniform(low=0, high=1, size=1) > rrr\n",
    "    elif x==0:\n",
    "        returnVal =  0\n",
    "    return returnVal\n",
    "\n",
    "# assign events based on the baseline risk and whether an event is in priomary or secondary pvention contesxt\n",
    "def assignEventAcrossPrimaryAndSecondaryPrevention(x):\n",
    "    riskForComparison = x.secondaryRisk if x.anySecondaryPrevention else x.baselineRisk\n",
    "    return np.random.uniform(low=0, high=1, size=1) < riskForComparison\n",
    "\n",
    "# assigns two variables for each time step, \n",
    "#\"noTreatmentTx\" = 'whether you have an event at a given period' WITHOUT treatment and \n",
    "#'treatment Tx' = whether you have an event at a given epoch WITH treamtent\n",
    "# also tracks whether a patient has entered into a secondary prevention context, but tracking whether they have a treated event\n",
    "def assignEventsForEpoch(t, timeSeries, rrrPrimaryPrevention ):\n",
    "    noTreatmentName = 'noTreatmentT' + str(t)\n",
    "    treatmentName = 'treatmentT' + str(t)\n",
    "\n",
    "    timeSeries[noTreatmentName] = (timeSeries.apply(assignEventAcrossPrimaryAndSecondaryPrevention, axis=1)).astype(int)\n",
    "    timeSeries[treatmentName] = (timeSeries[noTreatmentName].apply(functools.partial(applyTreatment, rrrPrimaryPrevention ))).astype(int)\n",
    "    timeSeries[('treatmentEffect' + str(t))] = timeSeries[noTreatmentName] - timeSeries[treatmentName]\n",
    "    timeSeries['anySecondaryPrevention'] = pd.DataFrame([timeSeries['anySecondaryPrevention'],timeSeries[treatmentName]]).max()\n",
    "\n",
    "\n",
    "# setup a dataframe that tracks individual \"patients\" across a wide format dataframe\n",
    "def setupPopulation(n=10000, baselineRisk = 0.10,secondaryRiskMultiplier = 2.0, rrrPrimaryPrevention = 0.20, durationOfFollowup = 10 ):\n",
    "    # setup the baseline risk\n",
    "    timeSeries = pd.DataFrame(data={'baselineRisk' : np.random.normal(loc=baselineRisk, scale=(0.04), size=n)})\n",
    "    timeSeries[timeSeries['baselineRisk'] < 0 ] = 0\n",
    "    timeSeries['secondaryRisk'] = timeSeries['baselineRisk'] * secondaryRiskMultiplier\n",
    "    # anySecondaryPRevention is a flag to track whether somebody ever had an event\n",
    "    timeSeries['anySecondaryPrevention'] = 0 # everybody starts in primary prevention\n",
    "    \n",
    "    for t in range(1, durationOfFollowup+1):\n",
    "        assignEventsForEpoch(t, timeSeries, rrrPrimaryPrevention)\n",
    "    \n",
    "    # keep track of the first wave when somebody had an event\n",
    "    conditions = [timeSeries[('treatmentT' + str(x))] ==1 for x in range(1, durationOfFollowup+1)]\n",
    "    timeSeries['strokeWave'] = (np.select(conditions, [x for x in range(1,durationOfFollowup+1)], default='0')).astype(int)\n",
    "    waveLabel={x:'stroke wave: ' + str(x) for x in range(1, durationOfFollowup+1)}\n",
    "    waveLabel[0] = 'no stroke'\n",
    "    timeSeries['strokeWaveLab'] = timeSeries['strokeWave'].apply(lambda x : waveLabel[x] )\n",
    "    # observed treatment effet is the average of the treatemnet event rates and untreated event rates\n",
    "    timeSeries['observedTreatmentEffect'] = timeSeries[['treatmentEffect' + str(t) for t in range(1, durationOfFollowup+1)]].sum(axis=1)/durationOfFollowup\n",
    "    # true causal effect = the effect that we wouild have expected before undertaking the sim\n",
    "    timeSeries['trueCausalEffect'] = timeSeries.baselineRisk * rrrPrimaryPrevention\n",
    "    return timeSeries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign events for the baseline simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "baselineAssumptionPopulations = setupPopulation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>observedTreatmentEffect</th>\n",
       "      <th>trueCausalEffect</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>strokeWave</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.019424</td>\n",
       "      <td>0.017517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.023472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.034450</td>\n",
       "      <td>0.022896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.037191</td>\n",
       "      <td>0.022727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.035364</td>\n",
       "      <td>0.022334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.030769</td>\n",
       "      <td>0.022087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.029752</td>\n",
       "      <td>0.021826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.028194</td>\n",
       "      <td>0.021831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.021964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.026992</td>\n",
       "      <td>0.021667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.020896</td>\n",
       "      <td>0.021322</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            observedTreatmentEffect  trueCausalEffect\n",
       "strokeWave                                           \n",
       "0                          0.019424          0.017517\n",
       "1                          0.045455          0.023472\n",
       "2                          0.034450          0.022896\n",
       "3                          0.037191          0.022727\n",
       "4                          0.035364          0.022334\n",
       "5                          0.030769          0.022087\n",
       "6                          0.029752          0.021826\n",
       "7                          0.028194          0.021831\n",
       "8                          0.023810          0.021964\n",
       "9                          0.026992          0.021667\n",
       "10                         0.020896          0.021322"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baselineAssumptionPopulations.groupby('strokeWave')[['observedTreatmentEffect','trueCausalEffect']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observedTreatmentEffect    0.026750\n",
      "trueCausalEffect           0.020133\n",
      "dtype: float64\n",
      "1.3286429047220631\n"
     ]
    }
   ],
   "source": [
    "overallResult = baselineAssumptionPopulations[['observedTreatmentEffect', 'trueCausalEffect']].mean()\n",
    "print (overallResult)\n",
    "print (overallResult['observedTreatmentEffect'] / overallResult['trueCausalEffect'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>observedTreatmentEffect</th>\n",
       "      <th>trueCausalEffect</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anySecondaryPrevention</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.019424</td>\n",
       "      <td>0.017517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.033036</td>\n",
       "      <td>0.022378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        observedTreatmentEffect  trueCausalEffect\n",
       "anySecondaryPrevention                                           \n",
       "0                                      0.019424          0.017517\n",
       "1                                      0.033036          0.022378"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baselineAssumptionPopulations.groupby('anySecondaryPrevention')[['observedTreatmentEffect','trueCausalEffect']].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>what we learn from the baseline population</b>\n",
    "<ol>\n",
    "    <li> overall treamtent effect is overestimated by 15%</li>\n",
    "    <li> the magnitude of overestimation is worse in teh secondary prevention than primary prevention population</li>\n",
    "    <li> there is a slight  overestimation of the treatment benefit in the population that never has a stroke because, the people at the highest “true” risk get pulled out of that population…the longer the follow-up the smaller this problem becomes.</li>\n",
    "<li> there is a large overestimation of the treatment benefit in the population that has a stroke in early waves</li>\n",
    "<li>the magnitude of the overestimation decreases in people that have events late, and in some scenarios there is underestimation</li>\n",
    "<li> in the baseline scenario (high baseline risk (10%) and long follow-up (10 years(), the overall (primary + secondary) observed treatment effect is over-estimated — by about 30%)</li> with a large baseline risk and a long follow-up\n",
    "</ol>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### exploring how the efect changes under different assumptions\n",
    "\n",
    "1. the magnitude of the problem is related to primary event rates. if we reduce the baseline event rate to 1%, the overestimation of treatment effect falls...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowBaselineRiskPopulation = setupPopulation(n=100000, baselineRisk = 0.01,secondaryRiskMultiplier = 2.0, rrrPrimaryPrevention = 0.20, durationOfFollowup = 10 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observedTreatmentEffect    0.005088\n",
      "trueCausalEffect           0.004297\n",
      "dtype: float64\n",
      "1.1840798565332977\n"
     ]
    }
   ],
   "source": [
    "lowBaselineResult = lowBaselineRiskPopulation[['observedTreatmentEffect', 'trueCausalEffect']].mean()\n",
    "print (lowBaselineResult)\n",
    "print (lowBaselineResult['observedTreatmentEffect'] / lowBaselineResult['trueCausalEffect'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. its also related to the difference in primary and secondary event rates, the magnitude of overestimation falls from 30% when secondary rates are double primary rates to 15% when they’re 1.5 times as high.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "smallerSecondaryRisk = setupPopulation(n=100000, baselineRisk = 0.10,secondaryRiskMultiplier = 1.5, rrrPrimaryPrevention = 0.20,  durationOfFollowup = 10 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observedTreatmentEffect    0.023219\n",
      "trueCausalEffect           0.020005\n",
      "dtype: float64\n",
      "1.1606692112762291\n"
     ]
    }
   ],
   "source": [
    "smallSecondaryResult = smallerSecondaryRisk[['observedTreatmentEffect', 'trueCausalEffect']].mean()\n",
    "print (smallSecondaryResult)\n",
    "print (smallSecondaryResult['observedTreatmentEffect'] / smallSecondaryResult['trueCausalEffect'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. it it essentially unrelated to treatment effect size in relative terms, but obviously important in absolute terms\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "smallerRRR = setupPopulation(n=100000, baselineRisk = 0.10,secondaryRiskMultiplier = 2.0, rrrPrimaryPrevention = 0.10, durationOfFollowup = 10 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observedTreatmentEffect    0.013432\n",
      "trueCausalEffect           0.010020\n",
      "dtype: float64\n",
      "1.3405416215382266\n"
     ]
    }
   ],
   "source": [
    "smalerRRRResult = smallerRRR[['observedTreatmentEffect', 'trueCausalEffect']].mean()\n",
    "print (smalerRRRResult)\n",
    "print (smalerRRRResult['observedTreatmentEffect'] / smalerRRRResult['trueCausalEffect'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. it is highly sensitive to how long the sim runs…at 3 years of follow-up, treatment effect is overestimated by 10% vs. 30% at 10 years (baseline) and 65% (!) at 30 years\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "shorterFollowup = setupPopulation(n=100000, baselineRisk = 0.10,secondaryRiskMultiplier = 2.0, rrrPrimaryPrevention = 0.20, durationOfFollowup = 3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observedTreatmentEffect    0.022043\n",
      "trueCausalEffect           0.019977\n",
      "dtype: float64\n",
      "1.1034379498225981\n"
     ]
    }
   ],
   "source": [
    "shorterFollowUpResult = shorterFollowup[['observedTreatmentEffect', 'trueCausalEffect']].mean()\n",
    "print (shorterFollowUpResult)\n",
    "print (shorterFollowUpResult['observedTreatmentEffect'] / shorterFollowUpResult['trueCausalEffect'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "longerFollowup = setupPopulation(n=100000, baselineRisk = 0.10,secondaryRiskMultiplier = 2.0, rrrPrimaryPrevention = 0.20,  durationOfFollowup = 30 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observedTreatmentEffect    0.032695\n",
      "trueCausalEffect           0.020003\n",
      "dtype: float64\n",
      "1.6366189002018148\n"
     ]
    }
   ],
   "source": [
    "longerFollowUpResult = longerFollowup[['observedTreatmentEffect', 'trueCausalEffect']].mean()\n",
    "print (longerFollowUpResult)\n",
    "print (longerFollowUpResult['observedTreatmentEffect'] / shorterFollowUpResult['trueCausalEffect'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>upshot:</b> there is a potential for this to cause pretty substantial treatment effect misestimation for us, given that we want to look at a relatively long time horizon and that our secondary vs. primary event differential is going to be pretty substantial. and we need to deal with...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to fix this? I think the idea is tat we need a joint model that accounts for boht event types.\n",
    "\n",
    "Best reference I've found so far: Amorim, L. D., & Cai, J. (2014). Modelling recurrent events: a tutorial for analysis in epidemiology. International Journal of Epidemiology, 44(1), 324–333. http://doi.org/10.1093/ije/dyu222\n",
    "\n",
    "I think that the model type that is going to work best is to stratify by primary secondary using a Prentice, Williams and Petersen model based on gap time. \n",
    "\n",
    "To do that, let's first export our data to stata nd then try to model this.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "baselineAssumptionPopulations['id'] = baselineAssumptionPopulations.index\n",
    "baselineAssumptionPopulations['treatmentT0'] = 0\n",
    "baselineAssumptionPopulations['noTreatmentT0'] = 0\n",
    "baselineAssumptionPopulations['treatmentEffect0'] = 0\n",
    "long = pd.wide_to_long(baselineAssumptionPopulations, stubnames=['treatmentT', 'noTreatmentT', 'treatmentEffect'],i='id', j='time' )\n",
    "long.sort_values(by=['id', 'time'])\n",
    "long['time2'] = long.index.get_level_values(1)\n",
    "long.loc[(long['time2'] > long['strokeWave'] ) & long['anySecondaryPrevention']==1, 'secondaryPrevention']= 1\n",
    "long['secondaryPrevention'] = long['secondaryPrevention'].fillna(0).astype(int)\n",
    "long.to_stata(\"simulatedDataOutput.dta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# redefine the function for assigning risk - from the baseline stata cox model with secondary prevention + baseline risk\n",
    "def assignEventAcrossPrimaryAndSecondaryPrevention(x):\n",
    "    riskForComparison = .0347954   * np.exp(x.baselineRisk* 9.603633     + x.anySecondaryPrevention*.7035687    )\n",
    "    return np.random.uniform(low=0, high=1, size=1) < riskForComparison\n",
    "\n",
    "modelBasedRiskPopulation = setupPopulation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>observedTreatmentEffect</th>\n",
       "      <th>trueCausalEffect</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anySecondaryPrevention</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.018357</td>\n",
       "      <td>0.017834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.031359</td>\n",
       "      <td>0.022014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        observedTreatmentEffect  trueCausalEffect\n",
       "anySecondaryPrevention                                           \n",
       "0                                      0.018357          0.017834\n",
       "1                                      0.031359          0.022014"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelBasedRiskPopulation.groupby('anySecondaryPrevention')[['observedTreatmentEffect','trueCausalEffect']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observedTreatmentEffect    0.025360\n",
      "trueCausalEffect           0.020085\n",
      "dtype: float64\n",
      "1.2626237273496566\n"
     ]
    }
   ],
   "source": [
    "overallResultJoint = modelBasedRiskPopulation[['observedTreatmentEffect', 'trueCausalEffect']].mean()\n",
    "print (overallResultJoint)\n",
    "print (overallResultJoint['observedTreatmentEffect'] / overallResultJoint['trueCausalEffect'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### so, a simple model barely fixed anything — it vfery slightly reduced the risk of overestimation...what if we try and interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# redefine the function for assigning risk - from the baseline stata cox model with secondary prevention + baseline risk\n",
    "def assignEventAcrossPrimaryAndSecondaryPrevention(x):\n",
    "    riskForComparison = .0325089 * np.exp(x.baselineRisk* 10.22063      + x.anySecondaryPrevention*.8669744 - x.anySecondaryPrevention*x.baselineRisk*-1.374077    )\n",
    "    return np.random.uniform(low=0, high=1, size=1) < riskForComparison\n",
    "\n",
    "modelBasedRiskWithInteractionPopulation = setupPopulation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
